{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f522b79-2a5a-4472-adb9-0d924870bfa1",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1727881526148,
    "lastExecutedByKernel": "7041c111-44bb-4574-8957-3984e7889c1e",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# # Make sure to run this cell to use torchmetrics.\n# !pip install torch torchvision torchmetrics",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# # Make sure to run this cell to use torchmetrics.\n",
    "!pip install torch torchvision torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1bedee-bcd5-4c80-a5ed-93df89af0295",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3927,
    "lastExecutedAt": 1727881370483,
    "lastExecutedByKernel": "7041c111-44bb-4574-8957-3984e7889c1e",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import required libraries\n# -------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# -------------------------\n",
    "# Data loading\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Train model\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluate model\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(101010)\n",
    "np.random.seed(101010)\n",
    "random.seed(101010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91680d-cb63-4876-9a51-4ee6bb250c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Unzip the data folder\n",
    "if not os.path.exists('data/chestxrays'):\n",
    "    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5591a-8dc1-4d7f-88d2-3b1a59fb2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations to apply to the images for use with ResNet-18\n",
    "transform_mean = [0.485, 0.456, 0.406]\n",
    "transform_std =[0.229, 0.224, 0.225]\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n",
    "\n",
    "# Apply the image transforms\n",
    "train_dataset = ImageFolder('data/chestxrays/train', transform=transform)\n",
    "test_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99cf95b-83f3-49e4-9777-4e70736452d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------\n",
    "# Q1: Instantiate the model\n",
    "#--------------------------\n",
    "\n",
    "# Load the pre-trained ResNet-18 model\n",
    "resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "#--------------------------\n",
    "# Q2: Modify the model\n",
    "#--------------------------\n",
    "\n",
    "# Freeze the parameters of the model\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final layer for binary classification\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 1)\n",
    "\n",
    "#------------------------------\n",
    "# Q3a: Define the training loop\n",
    "#------------------------------\n",
    "\n",
    "# Model training/fine-tuning loop\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    # Train the model for the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to train mode\n",
    "        model.train()\n",
    "\n",
    "        # Initialize the running loss and accuracy\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0\n",
    "\n",
    "        # Iterate over the batches of the train loader\n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            # Zero the optimizer gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Ensure labels have the same dimensions as outputs\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs) > 0.5 # Binary classification\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimizer step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the running loss and accuracy\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_accuracy += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Calculate the train loss and accuracy for the current epoch\n",
    "        train_loss = running_loss / len(train_dataset)\n",
    "        train_acc = running_accuracy.double() / len(train_dataset)\n",
    "\n",
    "        # Print the epoch results\n",
    "        print('Epoch [{}/{}], train loss: {:.4f}, train acc: {:.4f}'\n",
    "              .format(epoch+1, num_epochs, train_loss, train_acc))\n",
    "\n",
    "#-------------------------\n",
    "# Q3b: Fine-tune the model\n",
    "#-------------------------        \n",
    "        \n",
    "# Set the model to ResNet-18\n",
    "model = resnet18\n",
    "\n",
    "# Fine-tune the ResNet-18 model for 3 epochs using the train_loader\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "train(model, train_loader, criterion, optimizer, num_epochs=3)\n",
    "\n",
    "#-----------------------\n",
    "# Evaluation code\n",
    "#----------------------- \n",
    "\n",
    "# Set model to evaluation mode\n",
    "model = resnet18\n",
    "model.eval()\n",
    "\n",
    "# Initialize metrics for accuracy and F1 score\n",
    "accuracy_metric = Accuracy(task=\"binary\")\n",
    "f1_metric = F1Score(task=\"binary\")\n",
    "\n",
    "# Create lists store all predictions and labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "  for inputs, labels in test_loader:\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n",
    "\n",
    "    # Extend the lists with predictions and labels\n",
    "    all_preds.extend(preds.tolist())\n",
    "    all_labels.extend(labels.unsqueeze(1).tolist())\n",
    "\n",
    "    # Convert lists back to tensors\n",
    "    all_preds = torch.tensor(all_preds)\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "\n",
    "    # Calculate accuracy and F1 score\n",
    "    test_accuracy = accuracy_metric(all_preds, all_labels).item()\n",
    "    test_f1_score = f1_metric(all_preds, all_labels).item()\n",
    " \n",
    "print(f\"\\nTest accuracy: {test_accuracy:.3f}\\nTest F1-score: {test_f1_score:.3f}\")\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "# Below is a sample code for the bonus task.\n",
    "# This code divides the training set into training and validation subsets.\n",
    "# You will have 150 examples per class for training and 50 for validation.\n",
    "# Don't forget to create new `val_dataset` and `val_loader` after running this code.\n",
    "#-----------------------------------------------------------------------------------\n",
    "'''\n",
    "import os, random, shutil\n",
    "\n",
    "# Function to move 50 random files from class folder in training to validation folder\n",
    "def move_files(src_class_dir, dest_class_dir, n=50):\n",
    "    if not os.path.exists(dest_class_dir):\n",
    "        os.makedirs(dest_class_dir)\n",
    "    files = os.listdir(src_class_dir)\n",
    "    random_files = random.sample(files, n)\n",
    "    for f in random_files:\n",
    "        shutil.move(os.path.join(src_class_dir, f), os.path.join(dest_class_dir, f))\n",
    "\n",
    "# Move 50 images from each class to validation folder\n",
    "move_files('data/chestxrays/train/NORMAL', 'data/chestxrays/val/NORMAL')\n",
    "move_files('data/chestxrays/train/PNEUMONIA', 'data/chestxrays/val/PNEUMONIA')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70761893-e66f-40fe-8862-dac9b18a13ab",
   "metadata": {},
   "source": [
    "### Below is the provided model evaluation code. Run the below cell to help you evaluate the accuracy and F1-score of your fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e1ad6-2f78-4a14-943b-8cc7c9dfe960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------\n",
    "# Evaluate the model\n",
    "#-------------------\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model = resnet18\n",
    "model.eval()\n",
    "\n",
    "# Initialize metrics for accuracy and F1 score\n",
    "accuracy_metric = Accuracy(task=\"binary\")\n",
    "f1_metric = F1Score(task=\"binary\")\n",
    "\n",
    "# Create lists store all predictions and labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "  for inputs, labels in test_loader:\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n",
    "\n",
    "    # Extend the lists with predictions and labels\n",
    "    all_preds.extend(preds.tolist())\n",
    "    all_labels.extend(labels.unsqueeze(1).tolist())\n",
    "\n",
    "    # Convert lists back to tensors\n",
    "    all_preds = torch.tensor(all_preds)\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "\n",
    "    # Calculate accuracy and F1 score\n",
    "    test_acc = accuracy_metric(all_preds, all_labels).item()\n",
    "    test_f1 = f1_metric(all_preds, all_labels).item()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
